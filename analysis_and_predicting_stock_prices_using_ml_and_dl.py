# -*- coding: utf-8 -*-
"""Analysis and Predicting Stock Prices using ML and DL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-RQw5QSE1OHMR2JMRs8X83-sYB-O6zGx
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import plotly.express as px
from scipy import stats
import matplotlib.pyplot as plt
import plotly.figure_factory as ff
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from tensorflow import keras

#Read stock prices data
stock_price_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/stock.csv')

stock_price_df.head()

#Read the stock volume data
stock_vol_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/stock_volume.csv')
stock_vol_df.head()

#sort the data based on Date
stock_price_df = stock_price_df.sort_values(by=['Date'])

stock_price_df.head()

#checking null values
stock_price_df.isnull().sum()

stock_vol_df.isnull().sum()

stock_price_df.info()

stock_vol_df.info()

stock_vol_df.describe()

"""## Task #3: Perform Exploratory Data Analysis And Visualization"""

#Function to normalize stock prices based on their initial price
def normalize(df):
  x = df.copy()
  for i in x.columns[1:]:
    x[i] = x[i]/x[i][0]
  return x

#Function to plot interactive plots using Plotly Express
def interactive_plot(df, title):
  fig = px.line(title = title)
  for i in df.columns[1:]:
    fig.add_scatter(x= df['Date'], y = df[i], name = i)
  fig.show()

#plot interactive chart for stock data
interactive_plot(stock_price_df, 'Stock Prices')

new_dataset = normalize(stock_price_df)

interactive_plot(new_dataset,"Stock Prices of Normalized Dataset")

interactive_plot(stock_vol_df, "Stock Volume Dataset")



new_dataset = normalize(stock_vol_df)

interactive_plot(new_dataset,"Stock Prices of Normalized Dataset")

"""## Task #4: Prepare the Data Before Training the AI/ML Model"""

#function to concatenate the date, stock price, and volume into one dataframw
def individual_stock(price_df, vol_df, name):
  return( pd.DataFrame({'Date':price_df['Date'],'Closing Price':price_df[name],"Volume":vol_df[name]}))

def trading_window(data):
  n = 1
  data['Target'] = data[['Closing Price']].shift(-n)

  return data

#let's test the function and get individual stock prices and volumes for AAPL
price_volume_df = individual_stock(stock_price_df, stock_vol_df,'AAPL')
price_volume_df

price_volume_target_df = trading_window(price_volume_df)
price_volume_target_df

#Remove the last row as it will be a null value
price_volume_target_df = price_volume_target_df[:-1]
price_volume_target_df

#Scale the Data
from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range=(0,1))
price_volume_target_scaled_df = sc.fit_transform(price_volume_target_df.drop(columns = ['Date']))

price_volume_target_scaled_df

price_volume_target_scaled_df.shape

#Create Feature and Target
X = price_volume_target_scaled_df[:,:2]
y = price_volume_target_scaled_df[:,2:]

X

y

X.shape

y.shape

#Spliting the data this way, since order is important in time-series
#Note that we did not use train_test_split with it's default settings since it's shuffles
split = int(0.65*len(X))
X_train = X[:split]
y_train = y[:split]
X_test = X[split:]
y_test = y[split:]

X_train.shape, y_train.shape

X_test.shape, y_test.shape

def show_plot(data, title):
  plt.figure(figsize=(13,5))
  plt.plot(data,linewidth = 3)
  plt.title(title)
  plt.figure()

show_plot(X_train,"Training Data")
show_plot(X_test,"Testing Data")



"""Analyzing Amazon Stock Prices"""

#let's test the function and get individual stock prices and volumes for AAPL
price_volume_df = individual_stock(stock_price_df, stock_vol_df,'AMZN')
price_volume_df



#Scale the Data
from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range=(0,1))
price_volume_target_scaled_df = sc.fit_transform(price_volume_target_df.drop(columns = ['Date']))

#Create Feature and Target
X = price_volume_target_scaled_df[:,:2]
y = price_volume_target_scaled_df[:,2:]

#Create Feature and Target
X = price_volume_target_scaled_df[:,:2]
y = price_volume_target_scaled_df[:,2:]

#Spliting the data this way, since order is important in time-series
#Note that we did not use train_test_split with it's default settings since it's shuffles
split = int(0.65*len(X))
X_train = X[:split]
y_train = y[:split]
X_test = X[split:]
y_test = y[split:]

def show_plot(data, title):
  plt.figure(figsize=(13,5))
  plt.plot(data,linewidth = 3)
  plt.title(title)
  plt.figure()

show_plot(X_train,"Training Data")
show_plot(X_test,"Testing Data")



"""Analyzing Sp500 Stocks"""

#let's test the function and get individual stock prices and volumes for AAPL
price_volume_df = individual_stock(stock_price_df, stock_vol_df,'sp500')
price_volume_df

#Scale the Data
from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range=(0,1))
price_volume_target_scaled_df = sc.fit_transform(price_volume_target_df.drop(columns = ['Date']))

#Create Feature and Target
X = price_volume_target_scaled_df[:,:2]
y = price_volume_target_scaled_df[:,2:]

#Create Feature and Target
X = price_volume_target_scaled_df[:,:2]
y = price_volume_target_scaled_df[:,2:]

#Spliting the data this way, since order is important in time-series
#Note that we did not use train_test_split with it's default settings since it's shuffles
split = int(0.65*len(X))
X_train = X[:split]
y_train = y[:split]
X_test = X[split:]
y_test = y[split:]

def show_plot(data, title):
  plt.figure(figsize=(13,5))
  plt.plot(data,linewidth = 3)
  plt.title(title)
  plt.figure()

show_plot(X_train,"Training Data")
show_plot(X_test,"Testing Data")

"""## Task 7: Build and Train a Ridge Linear Regression Model"""

from sklearn.linear_model import Ridge
regression_model = Ridge()
regression_model.fit(X_train,y_train)

#Testing the model and calculate it's accuracy
lr_accuracy = regression_model.score(X_test,y_test)
print("Linear Regression Model", lr_accuracy)

#Make Prediction
predicted_prices = regression_model.predict(X)
predicted_prices

#Append the predict values into a list
predicted = []
for i in predicted_prices:
  predicted.append(i[0])

#Append the close values to the list
close = []
for i in price_volume_target_scaled_df:
  close.append(i[0])

#Create a dataframe
df_predicted = price_volume_target_df[['Date']]

df_predicted

#Add the predicted values to the dataframe
df_predicted['Prediction'] = predicted
df_predicted

#Add the close values to the dataframe
df_predicted['Close'] = close
df_predicted

# Plot the results
interactive_plot(df_predicted, "Original Vs. Prediction")



from sklearn.linear_model import Ridge
regression_model = Ridge(alpha=3)
regression_model.fit(X_train,y_train)

#Testing the model and calculate it's accuracy
lr_accuracy = regression_model.score(X_test,y_test)
print("Linear Regression Model", lr_accuracy)

#Make Prediction
predicted_prices = regression_model.predict(X)
predicted_prices

#Append the predict values into a list
predicted = []
for i in predicted_prices:
  predicted.append(i[0])

#Append the close values to the list
close = []
for i in price_volume_target_scaled_df:
  close.append(i[0])

#Create a dataframe
df_predicted = price_volume_target_df[['Date']]

#Add the predicted values to the dataframe
df_predicted['Prediction'] = predicted
df_predicted

#Add the close values to the dataframe
df_predicted['Close'] = close
df_predicted

# Plot the results
interactive_plot(df_predicted, "Original Vs. Prediction")

"""## Using RNN LSTM for the Time Series Model"""

# let's test the function and get individual stock prices and volumes for APPL
price_volume_df = individual_stock(stock_price_df,stock_vol_df,'sp500')
price_volume_df



#Get the close and volume data as training data(Input)
training_data = price_volume_df.iloc[:,1:3].values
training_data

#Normalize the  data
from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range= (0,1))
training_set_scaled = sc.fit_transform(training_data)

#Create the training and testing data, training data contains present day and previous day values
X=[]
y=[]
for i in range(1,len(price_volume_df)):
  X.append(training_set_scaled[i-1:i,0])
  y.append(training_set_scaled[i,0])

X

#convert the data into array format
X=np.asarray(X)
y = np.asarray(y)

#split the data
split = int(0.7 * len(X))
X_train = X[:split]
y_train = y[:split]
X_test = X[split:]
y_test = y[split:]

X_train.shape

y_train.shape

# Reshape the 1D arrays to 3D arrays to feed in the model
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
X_train.shape, X_test.shape

#Create the Model
inputs = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2]))
x = keras.layers.LSTM(150, return_sequences=True)(inputs)
x = keras.layers.Dropout(0.3)(x)
x= keras.layers.LSTM(150, return_sequences=True)(x)
x = keras.layers.Dropout(0.3)(x)
x = keras.layers.LSTM(150)(x)
outputs = keras.layers.Dense(1, activation='linear')(x)

model = keras.Model(inputs = inputs, outputs = outputs)
model.compile(optimizer = 'adam', loss = "mse")
model.summary()

# Train the model
history = model.fit(
    X_train, y_train,
    epochs = 20,
    batch_size = 32,
    validation_split = 0.2
)

# Make prediction
predicted = model.predict(X)

predicted

#Append the predicted values to the list
test_predicted = []

for i in predicted:
  test_predicted.append(i[0])

test_predicted



df_predicted['predictions'] = test_predicted

df_predicted

# Plot the data
close = []
for i in training_set_scaled:
  close.append(i[0])

df_predicted['Close'] = close[1:]

df_predicted

df_predicted

# Plot the data
interactive_plot(df_predicted, "Original Vs Prediction")



# let's test the function and get individual stock prices and volumes for APPL
price_volume_df = individual_stock(stock_price_df,stock_vol_df,'AMZN')
price_volume_df

#Get the close and volume data as training data(Input)
training_data = price_volume_df.iloc[:,1:3].values
training_data

#Normalize the  data
from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range= (0,1))
training_set_scaled = sc.fit_transform(training_data)

#Create the training and testing data, training data contains present day and previous day values
X=[]
y=[]
for i in range(1,len(price_volume_df)):
  X.append(training_set_scaled[i-1:i,0])
  y.append(training_set_scaled[i,0])

#convert the data into array format
X=np.asarray(X)
y = np.asarray(y)

#split the data
split = int(0.7 * len(X))
X_train = X[:split]
y_train = y[:split]
X_test = X[split:]
y_test = y[split:]

# Reshape the 1D arrays to 3D arrays to feed in the model
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
X_train.shape, X_test.shape

#Create the Model
inputs = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2]))
x = keras.layers.LSTM(150, return_sequences=True)(inputs)
x = keras.layers.Dropout(0.3)(x)
x= keras.layers.LSTM(150, return_sequences=True)(x)
x = keras.layers.Dropout(0.3)(x)
x = keras.layers.LSTM(150)(x)
outputs = keras.layers.Dense(1, activation='linear')(x)

model = keras.Model(inputs = inputs, outputs = outputs)
model.compile(optimizer = 'adam', loss = "mse")
model.summary()

# Train the model
history = model.fit(
    X_train, y_train,
    epochs = 20,
    batch_size = 32,
    validation_split = 0.2
)

# Make prediction
predicted = model.predict(X)

#Append the predicted values to the list
test_predicted = []

for i in predicted:
  test_predicted.append(i[0])

df_predicted['predictions'] = test_predicted

# Plot the data
close = []
for i in training_set_scaled:
  close.append(i[0])

df_predicted['Close'] = close[1:]

df_predicted

# Plot the data
interactive_plot(df_predicted, "Original Vs Prediction")



# let's test the function and get individual stock prices and volumes for APPL
price_volume_df = individual_stock(stock_price_df,stock_vol_df,'AAPL')
price_volume_df

#Get the close and volume data as training data(Input)
training_data = price_volume_df.iloc[:,1:3].values
training_data

#Normalize the  data
from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range= (0,1))
training_set_scaled = sc.fit_transform(training_data)

#Create the training and testing data, training data contains present day and previous day values
X=[]
y=[]
for i in range(1,len(price_volume_df)):
  X.append(training_set_scaled[i-1:i,0])
  y.append(training_set_scaled[i,0])

#convert the data into array format
X=np.asarray(X)
y = np.asarray(y)

#split the data
split = int(0.7 * len(X))
X_train = X[:split]
y_train = y[:split]
X_test = X[split:]
y_test = y[split:]

# Reshape the 1D arrays to 3D arrays to feed in the model
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
X_train.shape, X_test.shape

#Create the Model
inputs = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2]))
x = keras.layers.LSTM(150, return_sequences=True)(inputs)
x = keras.layers.Dropout(0.3)(x)
x= keras.layers.LSTM(150, return_sequences=True)(x)
x = keras.layers.Dropout(0.3)(x)
x = keras.layers.LSTM(150)(x)
outputs = keras.layers.Dense(1, activation='linear')(x)

model = keras.Model(inputs = inputs, outputs = outputs)
model.compile(optimizer = 'adam', loss = "mse")
model.summary()

# Train the model
history = model.fit(
    X_train, y_train,
    epochs = 20,
    batch_size = 32,
    validation_split = 0.2
)

# Make prediction
predicted = model.predict(X)

#Append the predicted values to the list
test_predicted = []

for i in predicted:
  test_predicted.append(i[0])

df_predicted['predictions'] = test_predicted

# Plot the data
close = []
for i in training_set_scaled:
  close.append(i[0])

df_predicted['Close'] = close[1:]

df_predicted

df_predicted.drop(['Prediction'],axis =1,inplace=True)

# Plot the data
interactive_plot(df_predicted, "Original Vs Prediction")

